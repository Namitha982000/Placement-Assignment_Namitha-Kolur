# -*- coding: utf-8 -*-
"""NLP_4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QonriHamYzwydzvIEFsbXWNjLe6qnk5_

# Question 4
"""

!pip install nltk

import re
from collections import Counter
import nltk
from nltk.tokenize import sent_tokenize
nltk.download('all')
def preprocess_text(text):
    # Remove special characters and punctuation
    text = re.sub(r'[^\w\s]', '', text)
    # Convert text to lowercase
    text = text.lower()
    return text

def generate_summary(text, num_sentences):
    # Preprocess the text
    preprocessed_text = preprocess_text(text)

    # Tokenize the text into sentences
    sentences = sent_tokenize(preprocessed_text)

    # Calculate scores for each sentence (using word frequency as an example)
    word_counts = Counter(preprocessed_text.split())
    sentence_scores = {sentence: sum(word_counts[word] for word in sentence.split()) for sentence in sentences}

    # Select top-ranked sentences based on scores
    selected_sentences = sorted(sentence_scores, key=sentence_scores.get, reverse=True)[:num_sentences]

    # Generate the summary by concatenating the selected sentences
    summary = ' '.join(selected_sentences)

    return summary

# Read the text file
with open('data.txt', 'r') as file:
    text = file.read()

# Specify the number of sentences to include in the summary
num_sentences = 3

# Generate the summary
summary = generate_summary(text, num_sentences)

# Print the summary
print("Summary:")
print(summary)

